{
  "timestamp": "2026-01-29T21:37:56.217949",
  "config": {
    "train_json": "./feasible/token_alignment/train_tokens_10q.json",
    "test_benchmark": "./feasible/token_alignment/test_tokens_10q.json",
    "output_dir": "feasible/token_alignment/task/10q_20260129_204744",
    "num_epochs": 50,
    "batch_size": 32,
    "learning_rate": 0.0001,
    "max_seq_len": 128,
    "embed_dim": 512,
    "num_layers": 4,
    "num_heads": 8,
    "device": "cuda",
    "max_train_samples": -1,
    "early_stopping": 999
  },
  "model_params": 45486346,
  "baseline": {
    "train": {
      "acceptance_rate": 0.08026301540891921,
      "total_correct": 151203,
      "total_tokens": 1883844
    },
    "test": {
      "acceptance_rate": 0.08047689280992,
      "total_correct": 32684,
      "total_tokens": 406129
    }
  },
  "final": {
    "train": {
      "dataset": "train",
      "num_samples": 52000,
      "acceptance_rate": 0.23237471638583931,
      "top5_rate": 0.5379731764222131,
      "total_correct": 535742,
      "total_tokens": 2305509,
      "inference_time_sec": 16.58767819404602,
      "samples_per_sec": 3134.857054235889,
      "timing_stats": {
        "eventgpt": {
          "stage1": {
            "mean": 0,
            "std": 0,
            "min": 0,
            "max": 0
          },
          "stage2": {
            "mean": 0,
            "std": 0,
            "min": 0,
            "max": 0
          },
          "stage3": {
            "mean": 0,
            "std": 0,
            "min": 0,
            "max": 0
          },
          "stage4": {
            "mean": 0,
            "std": 0,
            "min": 0,
            "max": 0
          },
          "stage5": {
            "mean": 0,
            "std": 0,
            "min": 0,
            "max": 0
          },
          "total": {
            "mean": 0,
            "std": 0,
            "min": 0,
            "max": 0
          }
        },
        "videollava": {
          "stage1": {
            "mean": 0,
            "std": 0,
            "min": 0,
            "max": 0
          },
          "stage2": {
            "mean": 0,
            "std": 0,
            "min": 0,
            "max": 0
          },
          "stage3": {
            "mean": 0,
            "std": 0,
            "min": 0,
            "max": 0
          },
          "stage4": {
            "mean": 0,
            "std": 0,
            "min": 0,
            "max": 0
          },
          "stage5": {
            "mean": 0,
            "std": 0,
            "min": 0,
            "max": 0
          },
          "total": {
            "mean": 0,
            "std": 0,
            "min": 0,
            "max": 0
          }
        }
      }
    },
    "test": {
      "dataset": "test",
      "num_samples": 11000,
      "acceptance_rate": 0.2148426450875014,
      "top5_rate": 0.5152292171403506,
      "total_correct": 104817,
      "total_tokens": 487878,
      "inference_time_sec": 3.463913917541504,
      "samples_per_sec": 3175.598545995969,
      "timing_stats": {
        "eventgpt": {
          "stage1": {
            "mean": 0,
            "std": 0,
            "min": 0,
            "max": 0
          },
          "stage2": {
            "mean": 0,
            "std": 0,
            "min": 0,
            "max": 0
          },
          "stage3": {
            "mean": 0,
            "std": 0,
            "min": 0,
            "max": 0
          },
          "stage4": {
            "mean": 0,
            "std": 0,
            "min": 0,
            "max": 0
          },
          "stage5": {
            "mean": 0,
            "std": 0,
            "min": 0,
            "max": 0
          },
          "total": {
            "mean": 0,
            "std": 0,
            "min": 0,
            "max": 0
          }
        },
        "videollava": {
          "stage1": {
            "mean": 0,
            "std": 0,
            "min": 0,
            "max": 0
          },
          "stage2": {
            "mean": 0,
            "std": 0,
            "min": 0,
            "max": 0
          },
          "stage3": {
            "mean": 0,
            "std": 0,
            "min": 0,
            "max": 0
          },
          "stage4": {
            "mean": 0,
            "std": 0,
            "min": 0,
            "max": 0
          },
          "stage5": {
            "mean": 0,
            "std": 0,
            "min": 0,
            "max": 0
          },
          "total": {
            "mean": 0,
            "std": 0,
            "min": 0,
            "max": 0
          }
        }
      }
    }
  },
  "training_history": [
    {
      "epoch": 1,
      "train_loss": 4.439818244347205,
      "train_acc": 0.2174397875735393,
      "val_acc": 0.2145208433255855,
      "val_top5": 0.5134295869049229
    },
    {
      "epoch": 2,
      "train_loss": 4.237301140124981,
      "train_acc": 0.22731606991474446,
      "val_acc": 0.21215549789086616,
      "val_top5": 0.5082725599432645
    },
    {
      "epoch": 3,
      "train_loss": 4.2091233560121974,
      "train_acc": 0.22935298820642325,
      "val_acc": 0.2148426450875014,
      "val_top5": 0.5152292171403506
    },
    {
      "epoch": 4,
      "train_loss": 4.192045441700862,
      "train_acc": 0.23064157121915083,
      "val_acc": 0.21471556413693588,
      "val_top5": 0.5168812694977023
    },
    {
      "epoch": 5,
      "train_loss": 4.1790099650162915,
      "train_acc": 0.23147062460275797,
      "val_acc": 0.2139202833495259,
      "val_top5": 0.5142679112401051
    },
    {
      "epoch": 6,
      "train_loss": 4.1672315879234905,
      "train_acc": 0.2325067204603782,
      "val_acc": 0.2141805943289101,
      "val_top5": 0.5157764851048828
    },
    {
      "epoch": 7,
      "train_loss": 4.158184488589947,
      "train_acc": 0.23332046748124635,
      "val_acc": 0.21202431755479853,
      "val_top5": 0.5109863531456634
    },
    {
      "epoch": 8,
      "train_loss": 4.149572323579054,
      "train_acc": 0.23390841926978184,
      "val_acc": 0.21437531514026048,
      "val_top5": 0.5121034356949893
    },
    {
      "epoch": 9,
      "train_loss": 4.140812824249267,
      "train_acc": 0.23455733821942257,
      "val_acc": 0.21428717835196504,
      "val_top5": 0.5110211979224314
    },
    {
      "epoch": 10,
      "train_loss": 4.133153862146231,
      "train_acc": 0.23509309343191293,
      "val_acc": 0.21371941345992235,
      "val_top5": 0.5128023809230996
    },
    {
      "epoch": 11,
      "train_loss": 4.125122058281532,
      "train_acc": 0.2357437754869461,
      "val_acc": 0.21295897744928036,
      "val_top5": 0.5128413250853697
    },
    {
      "epoch": 12,
      "train_loss": 4.117594867853018,
      "train_acc": 0.2361682673876102,
      "val_acc": 0.21267611984963453,
      "val_top5": 0.5121157338514957
    },
    {
      "epoch": 13,
      "train_loss": 4.110145070296068,
      "train_acc": 0.2368007355745022,
      "val_acc": 0.21141760850048577,
      "val_top5": 0.5089817536351301
    },
    {
      "epoch": 14,
      "train_loss": 4.10270226595952,
      "train_acc": 0.23719720989007217,
      "val_acc": 0.2133258724517195,
      "val_top5": 0.5116340560549973
    },
    {
      "epoch": 15,
      "train_loss": 4.095315305269682,
      "train_acc": 0.23775269444172198,
      "val_acc": 0.21388543857275794,
      "val_top5": 0.51161970820574
    },
    {
      "epoch": 16,
      "train_loss": 4.088599266198965,
      "train_acc": 0.23862897651012127,
      "val_acc": 0.21424823418969496,
      "val_top5": 0.5098426245905738
    },
    {
      "epoch": 17,
      "train_loss": 4.081229683215802,
      "train_acc": 0.23876242324022146,
      "val_acc": 0.21307171055058846,
      "val_top5": 0.512345299439614
    },
    {
      "epoch": 18,
      "train_loss": 4.073902310004601,
      "train_acc": 0.23951399807746593,
      "val_acc": 0.2110384153415403,
      "val_top5": 0.5043146032409742
    },
    {
      "epoch": 19,
      "train_loss": 4.067588291168213,
      "train_acc": 0.24016620065615726,
      "val_acc": 0.21327463013294307,
      "val_top5": 0.5116525032897569
    },
    {
      "epoch": 20,
      "train_loss": 4.060322786624615,
      "train_acc": 0.2405592273932237,
      "val_acc": 0.21122288768913539,
      "val_top5": 0.5068644210232887
    },
    {
      "epoch": 21,
      "train_loss": 4.054060973387498,
      "train_acc": 0.24115929916271797,
      "val_acc": 0.21245885241802254,
      "val_top5": 0.5085615666211635
    },
    {
      "epoch": 22,
      "train_loss": 4.047278055924636,
      "train_acc": 0.2421347915667754,
      "val_acc": 0.21068381849560752,
      "val_top5": 0.506661501440934
    },
    {
      "epoch": 23,
      "train_loss": 4.040861009157621,
      "train_acc": 0.24287307210151965,
      "val_acc": 0.21211040465034292,
      "val_top5": 0.5083094544127835
    },
    {
      "epoch": 24,
      "train_loss": 4.035334349705622,
      "train_acc": 0.24295805863233713,
      "val_acc": 0.21142580727149,
      "val_top5": 0.5071944215562088
    },
    {
      "epoch": 25,
      "train_loss": 4.028834041742178,
      "train_acc": 0.24398135151312902,
      "val_acc": 0.21108145888931248,
      "val_top5": 0.5072723098807489
    },
    {
      "epoch": 26,
      "train_loss": 4.023299324182363,
      "train_acc": 0.2445178140585239,
      "val_acc": 0.21207760956632601,
      "val_top5": 0.5073706951327996
    },
    {
      "epoch": 27,
      "train_loss": 4.018058387903067,
      "train_acc": 0.24504986236645626,
      "val_acc": 0.21248549842378628,
      "val_top5": 0.5066819983684445
    },
    {
      "epoch": 28,
      "train_loss": 4.012533195789044,
      "train_acc": 0.2456394880093061,
      "val_acc": 0.21219649174588728,
      "val_top5": 0.5079159134045806
    },
    {
      "epoch": 29,
      "train_loss": 4.007460049555852,
      "train_acc": 0.24635733841015742,
      "val_acc": 0.21207146048807285,
      "val_top5": 0.5063683953775329
    },
    {
      "epoch": 30,
      "train_loss": 4.002574595524715,
      "train_acc": 0.24689443128842573,
      "val_acc": 0.21145245327725373,
      "val_top5": 0.507708894436724
    },
    {
      "epoch": 31,
      "train_loss": 3.9978596360133243,
      "train_acc": 0.2475687448795025,
      "val_acc": 0.21189928629698407,
      "val_top5": 0.506263861047229
    },
    {
      "epoch": 32,
      "train_loss": 3.9934472487523007,
      "train_acc": 0.24789916166892417,
      "val_acc": 0.2113458692541988,
      "val_top5": 0.5050914367936247
    },
    {
      "epoch": 33,
      "train_loss": 3.9894032271458553,
      "train_acc": 0.24824107452539299,
      "val_acc": 0.21149344713227486,
      "val_top5": 0.5051734245036669
    },
    {
      "epoch": 34,
      "train_loss": 3.9851662358504076,
      "train_acc": 0.24894548963583432,
      "val_acc": 0.21024313455413032,
      "val_top5": 0.5046425540811432
    },
    {
      "epoch": 35,
      "train_loss": 3.9812394737830528,
      "train_acc": 0.24946475159204923,
      "val_acc": 0.2105280418465272,
      "val_top5": 0.5043760940235059
    },
    {
      "epoch": 36,
      "train_loss": 3.977928275034978,
      "train_acc": 0.2497619058260551,
      "val_acc": 0.21050344553351452,
      "val_top5": 0.5049049147532785
    },
    {
      "epoch": 37,
      "train_loss": 3.9747159555875338,
      "train_acc": 0.25036072326623476,
      "val_acc": 0.21097897425175965,
      "val_top5": 0.5041895719831597
    },
    {
      "epoch": 38,
      "train_loss": 3.9717822179060716,
      "train_acc": 0.25058618177817416,
      "val_acc": 0.21097487486625754,
      "val_top5": 0.5048823681330169
    },
    {
      "epoch": 39,
      "train_loss": 3.969235703101525,
      "train_acc": 0.25093290716868183,
      "val_acc": 0.21144630419900057,
      "val_top5": 0.5052984557614814
    },
    {
      "epoch": 40,
      "train_loss": 3.9669701090592606,
      "train_acc": 0.25133901373239664,
      "val_acc": 0.2112331361528907,
      "val_top5": 0.5046200074608816
    },
    {
      "epoch": 41,
      "train_loss": 3.9644496046213002,
      "train_acc": 0.2514976936303652,
      "val_acc": 0.21043990505823176,
      "val_top5": 0.5056018102886377
    },
    {
      "epoch": 42,
      "train_loss": 3.9624029705341046,
      "train_acc": 0.2518049609386004,
      "val_acc": 0.2109215828547301,
      "val_top5": 0.5051098840283842
    },
    {
      "epoch": 43,
      "train_loss": 3.9605400154407207,
      "train_acc": 0.2520368650509761,
      "val_acc": 0.21050139584076347,
      "val_top5": 0.5044355351132865
    },
    {
      "epoch": 44,
      "train_loss": 3.9591668721712554,
      "train_acc": 0.25221516556923207,
      "val_acc": 0.2108313963736836,
      "val_top5": 0.5046179577681306
    },
    {
      "epoch": 45,
      "train_loss": 3.958106488447923,
      "train_acc": 0.25217318365207086,
      "val_acc": 0.210774004976654,
      "val_top5": 0.5046732994724091
    },
    {
      "epoch": 46,
      "train_loss": 3.957330060518705,
      "train_acc": 0.25252776654867026,
      "val_acc": 0.21036816581194479,
      "val_top5": 0.5047962810374724
    },
    {
      "epoch": 47,
      "train_loss": 3.9561043560321516,
      "train_acc": 0.25286446328346546,
      "val_acc": 0.21045220321473812,
      "val_top5": 0.5045216222088309
    },
    {
      "epoch": 48,
      "train_loss": 3.955396358049833,
      "train_acc": 0.25243308954055493,
      "val_acc": 0.210519843075523,
      "val_top5": 0.5047675853389577
    },
    {
      "epoch": 49,
      "train_loss": 3.9550243594829855,
      "train_acc": 0.25276710203060737,
      "val_acc": 0.21042555720897438,
      "val_top5": 0.5047286411766876
    },
    {
      "epoch": 50,
      "train_loss": 3.954761363689716,
      "train_acc": 0.25305428526034723,
      "val_acc": 0.21037021550469584,
      "val_top5": 0.5047122436346791
    }
  ],
  "best_val_acc": 0.2148426450875014
}