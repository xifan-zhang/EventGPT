{
  "timestamp": "2026-01-27T21:53:39.583008",
  "config": {
    "train_json": "./feasible/benchmark_inference/benchmark_results_S1_train.json",
    "test_benchmark": "./feasible/benchmark_parallel_prefill/results/parallel_prefill_5stages_20260127_160820.json",
    "output_dir": "./feasible/token_alignment/results_1s",
    "num_epochs": 50,
    "batch_size": 32,
    "learning_rate": 0.0001,
    "max_seq_len": 128,
    "embed_dim": 512,
    "num_layers": 4,
    "num_heads": 8,
    "device": "cuda",
    "max_train_samples": -1,
    "early_stopping": 10
  },
  "model_params": 45476096,
  "baseline": {
    "train": {
      "acceptance_rate": 0.036976617727025554,
      "total_correct": 340,
      "total_tokens": 9195
    },
    "test": {
      "acceptance_rate": 0.015776957135399547,
      "total_correct": 816,
      "total_tokens": 51721
    }
  },
  "final": {
    "train": {
      "dataset": "train",
      "num_samples": 200,
      "acceptance_rate": 0.13785406022124114,
      "top5_rate": 0.32848851629545117,
      "total_correct": 2779,
      "total_tokens": 20159,
      "inference_time_sec": 0.0719749927520752,
      "samples_per_sec": 2778.7428987859616,
      "timing_stats": {
        "eventgpt": {
          "stage1": {
            "mean": 0.02613036036491394,
            "std": 0.06192510427538946,
            "min": 0.009361028671264648,
            "max": 0.5594165325164795
          },
          "stage2": {
            "mean": 0.019584563970565797,
            "std": 0.0035243073078514687,
            "min": 0.016044139862060547,
            "max": 0.034488677978515625
          },
          "stage3": {
            "mean": 1.013675241470337,
            "std": 0.15769441624424246,
            "min": 0.6088948249816895,
            "max": 1.4569242000579834
          },
          "stage4": {
            "mean": 0,
            "std": 0,
            "min": 0,
            "max": 0
          },
          "stage5": {
            "mean": 0,
            "std": 0,
            "min": 0,
            "max": 0
          },
          "total": {
            "mean": 1.059934868812561,
            "std": 0.17243231269564754,
            "min": 0.6559593677520752,
            "max": 1.6640324592590332
          }
        },
        "videollava": {
          "stage1": {
            "mean": 0.798645658493042,
            "std": 0.06832461170729445,
            "min": 0.7064907550811768,
            "max": 1.4154198169708252
          },
          "stage2": {
            "mean": 0.06974869608879089,
            "std": 0.003997412698780727,
            "min": 0.06623482704162598,
            "max": 0.11048030853271484
          },
          "stage3": {
            "mean": 2.5280013060569764,
            "std": 0.4377522037812383,
            "min": 1.0543262958526611,
            "max": 4.0296242237091064
          },
          "stage4": {
            "mean": 0,
            "std": 0,
            "min": 0,
            "max": 0
          },
          "stage5": {
            "mean": 0,
            "std": 0,
            "min": 0,
            "max": 0
          },
          "total": {
            "mean": 3.3986748003959657,
            "std": 0.44950124430368715,
            "min": 1.9185810089111328,
            "max": 4.98068642616272
          }
        }
      }
    },
    "test": {
      "dataset": "test",
      "num_samples": 1100,
      "acceptance_rate": 0.26658627087198516,
      "top5_rate": 0.4391280148423006,
      "total_correct": 14369,
      "total_tokens": 53900,
      "inference_time_sec": 0.4065124988555908,
      "samples_per_sec": 2705.943859282819,
      "timing_stats": {
        "eventgpt": {
          "stage1": {
            "mean": 0.0018005113168196244,
            "std": 0.00011176966362094382,
            "min": 0.0015196800231933594,
            "max": 0.003943920135498047
          },
          "stage2": {
            "mean": 0.00360513990575617,
            "std": 0.0001374204185075655,
            "min": 0.003378629684448242,
            "max": 0.006034374237060547
          },
          "stage3": {
            "mean": 0.00808354226025668,
            "std": 0.0035466667205553103,
            "min": 0.007628202438354492,
            "max": 0.11944079399108887
          },
          "stage4": {
            "mean": 0.08317118427970192,
            "std": 0.001777356503263059,
            "min": 0.08276748657226562,
            "max": 0.14086699485778809
          },
          "stage5": {
            "mean": 0.47292239796031604,
            "std": 0.04392448799175971,
            "min": 0.19424676895141602,
            "max": 0.5254316329956055
          },
          "total": {
            "mean": 0.5695827757228504,
            "std": 0.04378485035548854,
            "min": 0.2918074131011963,
            "max": 0.6215682029724121
          }
        },
        "videollava": {
          "stage1": {
            "mean": 0.07931291016665372,
            "std": 0.01566843976534015,
            "min": 0.05580568313598633,
            "max": 0.135728120803833
          },
          "stage2": {
            "mean": 0.06230532321062955,
            "std": 0.001514925191507427,
            "min": 0.05910801887512207,
            "max": 0.09553980827331543
          },
          "stage3": {
            "mean": 3.247261047363281e-06,
            "std": 2.55893633164715e-07,
            "min": 2.6226043701171875e-06,
            "max": 6.67572021484375e-06
          },
          "stage4": {
            "mean": 0.3155183564532887,
            "std": 0.0011021341754483308,
            "min": 0.3146703243255615,
            "max": 0.34641456604003906
          },
          "stage5": {
            "mean": 0.7239902622049506,
            "std": 0.0016477942394761953,
            "min": 0.7207469940185547,
            "max": 0.7385053634643555
          },
          "total": {
            "mean": 1.1811300992965699,
            "std": 0.016410350969566,
            "min": 1.156480073928833,
            "max": 1.2599706649780273
          }
        }
      }
    }
  },
  "training_history": [
    {
      "epoch": 1,
      "train_loss": 9.754806518554688,
      "train_acc": 0.06292507331818342,
      "val_acc": 0.08714285714285715,
      "val_top5": 0.3630055658627087
    },
    {
      "epoch": 2,
      "train_loss": 8.73370783669608,
      "train_acc": 0.08318886054413659,
      "val_acc": 0.10476808905380335,
      "val_top5": 0.3632096474953618
    },
    {
      "epoch": 3,
      "train_loss": 8.192150933401924,
      "train_acc": 0.09145384814058032,
      "val_acc": 0.15730983302411874,
      "val_top5": 0.3833395176252319
    },
    {
      "epoch": 4,
      "train_loss": 7.649253640856061,
      "train_acc": 0.11293689267975944,
      "val_acc": 0.20588126159554732,
      "val_top5": 0.3934508348794063
    },
    {
      "epoch": 5,
      "train_loss": 7.135844435010638,
      "train_acc": 0.12084537212337766,
      "val_acc": 0.2409090909090909,
      "val_top5": 0.4214100185528757
    },
    {
      "epoch": 6,
      "train_loss": 6.6874767030988425,
      "train_acc": 0.12712356554610388,
      "val_acc": 0.24185528756957328,
      "val_top5": 0.4251948051948052
    },
    {
      "epoch": 7,
      "train_loss": 6.329396860940116,
      "train_acc": 0.12542812632662909,
      "val_acc": 0.24168831168831167,
      "val_top5": 0.42597402597402595
    },
    {
      "epoch": 8,
      "train_loss": 6.056290285927909,
      "train_acc": 0.1293754375406674,
      "val_acc": 0.2584786641929499,
      "val_top5": 0.4374768089053803
    },
    {
      "epoch": 9,
      "train_loss": 5.8584378106253485,
      "train_acc": 0.1315745743257659,
      "val_acc": 0.2642486085343228,
      "val_top5": 0.4387569573283859
    },
    {
      "epoch": 10,
      "train_loss": 5.733770711081369,
      "train_acc": 0.13465444956507003,
      "val_acc": 0.2617254174397032,
      "val_top5": 0.4386270871985158
    },
    {
      "epoch": 11,
      "train_loss": 5.654057775224958,
      "train_acc": 0.13849530581917083,
      "val_acc": 0.26653061224489794,
      "val_top5": 0.4352319109461967
    },
    {
      "epoch": 12,
      "train_loss": 5.641448429652622,
      "train_acc": 0.1358063668012619,
      "val_acc": 0.26658627087198516,
      "val_top5": 0.4391280148423006
    },
    {
      "epoch": 13,
      "train_loss": 5.600127560751779,
      "train_acc": 0.1388556169612067,
      "val_acc": 0.25421150278293136,
      "val_top5": 0.43417439703153987
    },
    {
      "epoch": 14,
      "train_loss": 5.560519218444824,
      "train_acc": 0.1420464494398662,
      "val_acc": 0.2616512059369202,
      "val_top5": 0.4440630797773655
    },
    {
      "epoch": 15,
      "train_loss": 5.557650361742292,
      "train_acc": 0.13636036749397004,
      "val_acc": 0.25539888682745826,
      "val_top5": 0.4397773654916512
    },
    {
      "epoch": 16,
      "train_loss": 5.518994535718646,
      "train_acc": 0.14107951521873474,
      "val_acc": 0.2548979591836735,
      "val_top5": 0.43760667903525047
    },
    {
      "epoch": 17,
      "train_loss": 5.502543245043073,
      "train_acc": 0.14348620069878443,
      "val_acc": 0.2506493506493506,
      "val_top5": 0.4357142857142857
    },
    {
      "epoch": 18,
      "train_loss": 5.497859818594796,
      "train_acc": 0.14164682158402034,
      "val_acc": 0.25269016697588126,
      "val_top5": 0.4384230055658627
    },
    {
      "epoch": 19,
      "train_loss": 5.464500972202846,
      "train_acc": 0.14122475257941655,
      "val_acc": 0.2455473098330241,
      "val_top5": 0.4338404452690167
    },
    {
      "epoch": 20,
      "train_loss": 5.468681199210031,
      "train_acc": 0.14330801793507167,
      "val_acc": 0.24777365491651207,
      "val_top5": 0.4362708719851577
    },
    {
      "epoch": 21,
      "train_loss": 5.443700722285679,
      "train_acc": 0.14298850085054124,
      "val_acc": 0.2479591836734694,
      "val_top5": 0.43528756957328385
    }
  ],
  "best_val_acc": 0.26658627087198516
}