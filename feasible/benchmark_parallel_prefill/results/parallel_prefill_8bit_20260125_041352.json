{
  "timestamp": "20260125_041352",
  "datetime": "2026-01-25 04:13:52",
  "config": {
    "quantization": "8bit",
    "max_samples": 1100,
    "device": "cuda",
    "dataset_dir": "./data/my_egpt_dsec_test/my_egpt_dsec_seq_1s"
  },
  "statistics": {},
  "results": [],
  "errors": [
    {
      "sample_idx": 0,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 46.31 MiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 42.31 MiB is free. Including non-PyTorch memory, this process has 22.59 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 2,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 42.31 MiB is free. Including non-PyTorch memory, this process has 22.59 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 3,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 42.31 MiB is free. Including non-PyTorch memory, this process has 22.59 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 4,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 22.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.91 GiB is allocated by PyTorch, and 220.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 42.31 MiB is free. Including non-PyTorch memory, this process has 22.59 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 5,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 22.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 212.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 22.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 6,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 22.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 190.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 22.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 7,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 22.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 8,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 20.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 9,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 20.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 205.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 20.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 10,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 20.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 11,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 20.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 199.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 20.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 12,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 195.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 13,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 197.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 14,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 15,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 16,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 18.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 17,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 18.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 18,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 18.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 196.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 18.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 19,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 18.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 188.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 18.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 20,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 18.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 21,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 18.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 22,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 18.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 23,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 18.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.90 GiB is allocated by PyTorch, and 229.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 18.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 24,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 18.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 25,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 18.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 26,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 212.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 32.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 27,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 28,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 29,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 30,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 31,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 206.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 32,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 33,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.91 GiB is allocated by PyTorch, and 232.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 34,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 35,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 36,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 37,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 38,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 195.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 39,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.91 GiB is allocated by PyTorch, and 224.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 40,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 41,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 42,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 191.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 43,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 207.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 44,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 45,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 215.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 46,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 47,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 211.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 48,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 49,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 50,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 198.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 51,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 198.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 52,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.97 GiB is allocated by PyTorch, and 162.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 53,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 54,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 88.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 55,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 56,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 32.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 57,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 32.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 58,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 32.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 59,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 52.31 MiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 60,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 52.31 MiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 61,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 52.31 MiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 62,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 63,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 64,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 65,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 185.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 66,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 187.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 67,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 16.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 68,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 16.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 197.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 16.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 69,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 50.31 MiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 70,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 50.31 MiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 71,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 50.31 MiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 72,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 50.31 MiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 73,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 50.31 MiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 74,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 50.31 MiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 75,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 10.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 76,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 10.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 77,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 10.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 185.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 10.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 78,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 10.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 79,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 50.31 MiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 80,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 50.31 MiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 81,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 50.31 MiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 82,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 30.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 83,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 10.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 224.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 30.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 84,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 10.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.91 GiB is allocated by PyTorch, and 226.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 10.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 85,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 10.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 214.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 10.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 86,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 10.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 192.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 10.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 87,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 10.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 188.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 10.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 88,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 10.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 89,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 10.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 190.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 10.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 90,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 91,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 92,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 93,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 94,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 95,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 96,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 194.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 97,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 206.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 98,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 48.31 MiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 99,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 48.31 MiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 100,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 48.31 MiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 101,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 48.31 MiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 102,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 48.31 MiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 103,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 48.31 MiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 104,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 48.31 MiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 105,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 206.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 106,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 107,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 108,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 109,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 110,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 111,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 177.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 112,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 48.31 MiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 113,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 198.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 48.31 MiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 114,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 115,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 116,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 117,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 118,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 181.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 119,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 120,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 121,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 194.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 122,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 123,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 176.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 124,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 48.31 MiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 125,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 48.31 MiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 126,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 163.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 48.31 MiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 127,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 190.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 128,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 28.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 129,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 18.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 130,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 18.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 131,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 16.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 169.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 36.31 MiB is free. Including non-PyTorch memory, this process has 22.59 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 132,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 16.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 200.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 16.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 133,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 16.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 134,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 16.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 135,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 16.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 136,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 16.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 137,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 16.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 214.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 16.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 138,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 16.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 139,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 16.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 140,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 16.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 203.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 16.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 141,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 16.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 142,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 16.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 211.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 16.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 143,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 16.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.90 GiB is allocated by PyTorch, and 230.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 16.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 144,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 16.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 145,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 16.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 146,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 16.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 147,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 198.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 148,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 196.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 149,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 202.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 46.31 MiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 150,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.91 GiB is allocated by PyTorch, and 219.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 151,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 185.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 152,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 208.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 153,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 154,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 155,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.91 GiB is allocated by PyTorch, and 210.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 156,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.91 GiB is allocated by PyTorch, and 218.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 157,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 158,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 188.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 159,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 196.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 160,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 196.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 161,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 206.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 162,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 184.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 163,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.91 GiB is allocated by PyTorch, and 211.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 164,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 165,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 208.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 166,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.91 GiB is allocated by PyTorch, and 217.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 167,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 168,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 169,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 170,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 171,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 172,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 173,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 174,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 175,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 196.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 176,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 177,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.97 GiB is allocated by PyTorch, and 163.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 178,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 189.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 179,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 180,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 181,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 182,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 183,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 184,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 185,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 186,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 187,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.97 GiB is allocated by PyTorch, and 170.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 188,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 189,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 190,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 191,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 210.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 192,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 174.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 193,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 194,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 195,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 196,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 197,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 198,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 217.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 199,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 195.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 200,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 181.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 201,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 202,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 205.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 203,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 203.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 204,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 205,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.98 GiB is allocated by PyTorch, and 158.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 206,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 207,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 208,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 209,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 190.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 210,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 211,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 212,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 213,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 214,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 215,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 216,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 186.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 217,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 218,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 219,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 220,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 221,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 177.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 222,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 182.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 223,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 224,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 225,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 207.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 226,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 227,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 228,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 229,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 230,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 88.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 231,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 205.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 232,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 233,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 185.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 234,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 174.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 235,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 236,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 175.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 237,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 238,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 186.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 239,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 182.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 240,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 241,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 242,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.97 GiB is allocated by PyTorch, and 169.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 243,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 244,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 245,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 246,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 247,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 248,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 190.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 249,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 250,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 251,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 177.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 252,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 253,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 254,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 255,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 213.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 256,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 257,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 258,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 259,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 260,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 261,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 197.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 262,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 214.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 263,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 264,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 265,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 266,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 187.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 267,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 192.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 268,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 214.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 269,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 270,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 271,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.98 GiB is allocated by PyTorch, and 155.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 272,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 273,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 199.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 274,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 275,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 173.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 276,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 211.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 277,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 194.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 278,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 279,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 280,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 188.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 281,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 282,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 283,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 284,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 285,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 286,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 200.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 287,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 288,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 289,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 184.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 290,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 214.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 291,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 292,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 188.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 293,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 189.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 294,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 207.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 295,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 296,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 297,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 298,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 299,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 300,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 301,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 206.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 302,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 189.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 303,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 304,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 197.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 305,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 306,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 198.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 307,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 308,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 309,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 310,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 311,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 192.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 312,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 173.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 313,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 188.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 314,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 190.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 315,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 316,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 208.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 317,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 318,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 199.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 319,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 203.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 320,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 191.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 321,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 322,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 323,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 324,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 325,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 326,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 191.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 327,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 328,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 329,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 330,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.97 GiB is allocated by PyTorch, and 168.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 331,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 332,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 333,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 334,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 180.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 335,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 199.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 336,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 337,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 199.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 338,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.97 GiB is allocated by PyTorch, and 168.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 339,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.97 GiB is allocated by PyTorch, and 168.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 340,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 341,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 342,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 343,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.91 GiB is allocated by PyTorch, and 227.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 344,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.97 GiB is allocated by PyTorch, and 166.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 345,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 346,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.97 GiB is allocated by PyTorch, and 161.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 347,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 187.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 348,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 349,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 350,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 351,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 352,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 353,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 354,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 355,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 356,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 357,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 358,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 181.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 359,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.97 GiB is allocated by PyTorch, and 164.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 360,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 175.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 361,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 362,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 363,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 364,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 173.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 365,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 366,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 367,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 197.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 368,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 369,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 195.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 370,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 371,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 372,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 373,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 374,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 375,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 376,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 377,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 378,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 171.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 379,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 380,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.98 GiB is allocated by PyTorch, and 156.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 381,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 382,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 203.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 383,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 212.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 384,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 385,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 386,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.97 GiB is allocated by PyTorch, and 171.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 387,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 388,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 389,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 214.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 390,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 391,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 210.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 392,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 199.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 393,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 187.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 394,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 395,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 396,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 212.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 397,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 184.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 398,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 399,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 196.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 400,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 401,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 12.31 MiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 402,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 170.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 46.31 MiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 403,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.91 GiB is allocated by PyTorch, and 210.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 404,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 405,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 172.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 406,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.91 GiB is allocated by PyTorch, and 209.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 407,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 408,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 187.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 409,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 410,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 206.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 411,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 412,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 413,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 414,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 169.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 415,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 190.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 416,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 189.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 417,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 202.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 418,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 419,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 420,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 174.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 421,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 189.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 422,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 423,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 424,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 425,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 426,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 427,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.91 GiB is allocated by PyTorch, and 212.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 428,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 429,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 430,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 431,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 182.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 432,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.97 GiB is allocated by PyTorch, and 157.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 433,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 434,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 435,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 436,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.90 GiB is allocated by PyTorch, and 221.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 437,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 438,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 439,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 440,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 441,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 208.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 442,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 443,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 196.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 444,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 445,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 446,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 447,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 448,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 196.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 449,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 189.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 450,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 451,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 185.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 452,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 46.31 MiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 453,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 46.31 MiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 454,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 46.31 MiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 455,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 46.31 MiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 456,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 46.31 MiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 457,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 46.31 MiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 458,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 46.31 MiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 459,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 46.31 MiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 460,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 46.31 MiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 461,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.91 GiB is allocated by PyTorch, and 216.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 46.31 MiB is free. Including non-PyTorch memory, this process has 22.58 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 462,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 205.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 463,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 173.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 464,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 183.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 465,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 466,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 467,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 468,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 186.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 469,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 470,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 471,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 472,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 473,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 474,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 475,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 476,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 477,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 478,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 479,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 204.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 480,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 162.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 481,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 182.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 482,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 483,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 484,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 485,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 486,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 186.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 487,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 187.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 488,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 489,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 490,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 169.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 491,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 492,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 493,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 193.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 494,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 203.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 495,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 496,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 497,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.97 GiB is allocated by PyTorch, and 154.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 498,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 202.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 499,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 176.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 500,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 501,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 186.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 502,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 503,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.90 GiB is allocated by PyTorch, and 222.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 504,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 178.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 505,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 188.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 506,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 205.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 507,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 508,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 163.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 509,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 179.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 510,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 188.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 511,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 512,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 199.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 513,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 514,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 191.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 515,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 516,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 517,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 518,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 519,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 520,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 184.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 521,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 184.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 522,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 523,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 188.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 524,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 525,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 205.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 526,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 186.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 527,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 528,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 529,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 530,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 531,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 532,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 197.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 533,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 534,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 194.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 535,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 536,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 205.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 537,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 198.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 538,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 539,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 175.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 540,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 541,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 190.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 542,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 203.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 543,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 544,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.91 GiB is allocated by PyTorch, and 212.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 545,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 197.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 546,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 547,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 548,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 549,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 550,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 196.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 551,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 552,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 553,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 554,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 190.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 555,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 556,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 195.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 557,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 558,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 559,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 560,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 561,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 562,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 563,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 564,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 207.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 565,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 183.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 566,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 182.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 567,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 568,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 569,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 570,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 571,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 187.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 572,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 167.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 573,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 178.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 574,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 197.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 575,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 576,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 577,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 578,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 579,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 194.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 580,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 581,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 582,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 195.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 583,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 584,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 179.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 585,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 196.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 586,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 587,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 588,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 589,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 590,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 591,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 592,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 593,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 594,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 595,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 180.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 596,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 597,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 598,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 599,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 600,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 601,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 602,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 196.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 603,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 604,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 192.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 605,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 196.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 606,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 607,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 608,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 609,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 610,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 201.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 611,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 612,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.91 GiB is allocated by PyTorch, and 217.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 613,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 171.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 614,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 183.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 615,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 616,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 204.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 617,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 171.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 618,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 619,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 620,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 621,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.91 GiB is allocated by PyTorch, and 211.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 622,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 172.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 623,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 198.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 624,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 625,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 626,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 627,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 158.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 628,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 629,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 630,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 631,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 191.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 632,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 633,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 634,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 635,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 636,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 182.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 637,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 200.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 638,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 639,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 640,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 26.31 MiB is free. Including non-PyTorch memory, this process has 22.60 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 167.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 128.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 132.31 MiB is free. Including non-PyTorch memory, this process has 22.50 GiB memory in use. Of the all"
    },
    {
      "sample_idx": 641,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 44.31 MiB is free. Including non-PyTorch memory, this process has 22.59 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 642,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 182.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 44.31 MiB is free. Including non-PyTorch memory, this process has 22.59 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 643,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 198.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 644,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 203.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 645,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 646,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 647,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 648,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 179.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 649,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 198.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 650,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 191.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 651,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 652,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 202.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 653,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 200.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 654,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 182.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 655,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 656,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 657,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 193.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 658,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 659,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 170.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 660,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 200.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 661,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 180.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 662,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 663,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 664,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 185.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 665,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 666,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 667,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 668,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 669,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 192.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 670,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 44.31 MiB is free. Including non-PyTorch memory, this process has 22.59 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 671,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 44.31 MiB is free. Including non-PyTorch memory, this process has 22.59 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 672,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 201.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 673,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 674,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 675,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 676,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 185.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 677,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 189.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 678,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 177.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 679,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 191.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 680,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 180.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 681,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 682,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 683,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 684,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 685,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 686,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 687,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 688,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 185.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 689,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 185.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 690,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 691,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 189.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 692,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 189.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 693,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 199.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 694,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 162.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 695,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 211.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 696,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 170.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 697,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 698,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 187.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 699,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 700,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 176.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 701,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 702,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 703,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 704,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 193.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 705,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 706,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 707,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 708,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 195.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 709,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 44.31 MiB is free. Including non-PyTorch memory, this process has 22.59 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 710,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 44.31 MiB is free. Including non-PyTorch memory, this process has 22.59 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 711,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 44.31 MiB is free. Including non-PyTorch memory, this process has 22.59 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 712,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 184.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 713,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 714,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 715,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 716,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 717,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 209.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 718,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 171.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 719,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 720,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 721,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 722,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 723,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 192.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 724,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 725,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 187.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 726,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 170.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 727,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 728,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 729,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 730,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 731,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 190.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 732,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 179.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 733,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 189.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 734,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 735,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 736,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 190.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 737,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 738,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 739,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 191.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 740,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 188.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 741,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 742,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 196.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 743,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 192.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 744,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 745,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 208.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 746,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.97 GiB is allocated by PyTorch, and 156.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 747,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 748,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 187.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 749,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 177.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 750,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 751,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 752,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 193.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 753,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.90 GiB is allocated by PyTorch, and 228.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 754,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 194.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 755,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 199.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 756,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 757,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 758,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 172.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 759,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 181.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 760,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 761,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 762,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 763,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.91 GiB is allocated by PyTorch, and 217.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 764,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 765,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 194.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 766,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 767,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.97 GiB is allocated by PyTorch, and 158.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 768,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 201.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 769,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 44.31 MiB is free. Including non-PyTorch memory, this process has 22.59 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 770,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 44.31 MiB is free. Including non-PyTorch memory, this process has 22.59 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 771,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 175.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 44.31 MiB is free. Including non-PyTorch memory, this process has 22.59 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 772,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 773,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 774,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 195.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 775,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 776,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.97 GiB is allocated by PyTorch, and 154.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 777,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 778,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 779,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 780,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 781,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 190.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 782,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 195.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 783,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 209.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 784,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 785,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 786,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 787,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 788,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 789,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 185.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 790,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 791,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 792,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 793,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.91 GiB is allocated by PyTorch, and 212.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 794,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 795,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 796,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 193.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 797,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 199.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 798,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 193.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 799,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 800,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 173.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 801,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 192.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 802,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 803,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 804,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 207.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 805,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 806,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 807,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 808,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 809,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 88.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 810,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 187.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 811,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 812,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 813,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.90 GiB is allocated by PyTorch, and 224.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 814,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 815,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 179.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 816,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 817,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 185.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 818,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 819,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 820,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 192.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 821,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 822,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 823,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.97 GiB is allocated by PyTorch, and 154.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 824,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 825,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 826,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 210.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 827,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 194.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 828,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 200.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 829,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 88.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 830,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 831,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.97 GiB is allocated by PyTorch, and 158.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 832,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 833,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 834,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 202.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 835,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 836,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 189.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 837,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 183.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 838,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 839,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 168.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 840,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 841,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 175.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 842,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 189.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 843,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 844,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 161.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 845,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 846,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 202.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 847,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 202.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 848,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 163.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 849,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 850,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 851,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 189.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 852,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 853,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 177.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 854,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 193.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 855,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 856,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 178.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 857,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 196.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 858,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 859,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 860,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 861,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 862,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 177.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 863,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 864,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.97 GiB is allocated by PyTorch, and 158.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 865,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 183.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 866,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 867,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 868,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 197.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 869,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 870,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 871,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 872,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.97 GiB is allocated by PyTorch, and 157.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 873,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 874,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 875,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 876,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 877,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 878,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 164.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 879,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 880,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 194.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 881,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 882,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 183.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 883,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 184.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 884,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 190.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 885,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 886,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 175.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 887,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 888,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 889,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 890,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 189.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 891,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.97 GiB is allocated by PyTorch, and 149.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 892,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 177.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 893,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 894,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 179.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 895,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 168.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 896,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 166.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 897,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 898,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 899,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 900,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 189.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 901,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 902,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 191.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 44.31 MiB is free. Including non-PyTorch memory, this process has 22.59 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 903,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 904,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 905,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 906,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 907,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 201.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 908,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 201.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 909,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 195.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 910,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.91 GiB is allocated by PyTorch, and 211.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 911,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 912,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 913,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 914,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 915,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 170.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 916,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 161.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 917,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 195.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 918,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 919,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 920,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 921,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 183.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 922,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 181.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 923,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 191.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 924,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 925,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 196.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 926,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 927,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 928,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.91 GiB is allocated by PyTorch, and 216.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 929,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 930,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 195.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 931,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 183.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 932,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 933,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 934,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 935,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 936,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.91 GiB is allocated by PyTorch, and 213.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.31 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 937,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.06 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 938,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 88.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.00 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 939,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.00 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 199.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.00 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 940,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.00 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 196.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.00 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 941,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.00 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 942,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.81 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 943,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 944,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 945,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 946,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 947,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 188.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 948,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 949,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 178.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 950,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 951,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 952,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 953,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 192.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 954,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.91 GiB is allocated by PyTorch, and 218.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 955,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 88.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 43.88 MiB is free. Including non-PyTorch memory, this process has 22.59 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 956,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 43.88 MiB is free. Including non-PyTorch memory, this process has 22.59 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 957,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 160.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 43.88 MiB is free. Including non-PyTorch memory, this process has 22.59 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 958,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 959,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 163.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 960,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 194.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 961,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 962,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 963,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 191.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 964,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 965,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 966,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 187.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 967,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 206.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 968,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 969,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 970,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 192.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 971,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 972,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 973,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 974,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 88.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 975,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 976,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 173.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 977,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 978,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 189.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 979,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 980,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 981,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 982,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 165.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 983,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 984,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 179.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 23.88 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 985,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.00 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 177.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.00 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 986,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.00 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 197.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.00 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 987,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 988,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 189.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 989,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 990,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 991,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 176.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 992,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 993,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 994,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 995,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 996,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 997,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 998,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 999,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1000,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1001,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 173.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1002,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1003,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 179.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1004,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 164.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1005,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 191.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1006,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 179.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1007,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 179.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1008,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1009,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1010,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 199.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1011,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 182.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1012,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 181.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1013,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1014,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1015,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1016,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 181.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1017,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 177.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1018,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1019,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 161.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1020,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.91 GiB is allocated by PyTorch, and 217.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1021,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1022,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 190.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1023,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1024,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1025,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 187.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1026,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1027,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1028,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1029,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.97 GiB is allocated by PyTorch, and 159.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1030,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 166.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1031,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 88.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1032,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 88.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 44.25 MiB is free. Including non-PyTorch memory, this process has 22.59 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1033,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 186.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 44.25 MiB is free. Including non-PyTorch memory, this process has 22.59 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1034,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 192.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1035,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 183.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1036,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1037,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 188.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1038,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1039,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1040,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1041,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 210.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1042,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1043,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1044,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1045,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1046,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 168.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1047,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1048,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1049,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1050,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1051,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1052,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1053,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 201.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1054,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 187.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1055,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1056,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1057,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1058,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1059,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 195.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1060,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1061,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1062,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 178.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1063,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1064,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1065,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1066,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 204.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1067,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 183.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1068,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1069,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 190.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1070,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 172.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1071,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 187.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1072,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 189.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1073,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 172.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1074,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.95 GiB is allocated by PyTorch, and 176.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1075,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 182.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1076,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1077,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1078,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1079,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 183.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1080,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 182.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1081,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 165.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1082,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.98 GiB is allocated by PyTorch, and 147.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1083,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1084,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1085,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1086,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1087,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 206.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1088,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1089,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1090,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1091,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1092,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1093,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.94 GiB is allocated by PyTorch, and 185.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1094,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 191.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1095,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 163.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1096,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1097,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.91 GiB is allocated by PyTorch, and 216.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1098,
      "egpt_error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the allocated memory 21.93 GiB is allocated by PyTorch, and 195.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    },
    {
      "sample_idx": 1099,
      "egpt_error": null,
      "vl_error": "CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.49 GiB of which 24.25 MiB is free. Including non-PyTorch memory, this process has 22.61 GiB memory in use. Of the alloc"
    }
  ]
}