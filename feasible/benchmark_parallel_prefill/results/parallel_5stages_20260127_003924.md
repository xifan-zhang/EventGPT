# Parallel Prefill 5-Stage Benchmark Report

**Date:** 2026-01-27 00:40:55
**Dataset:** my_egpt_dsec_seq_1s
**Samples:** 0
**Max New Tokens:** 50

## Configuration

| Setting | Value |
|---------|-------|
| Dataset | my_egpt_dsec_seq_1s |
| Max Samples | 3 |
| Max New Tokens | 50 |
| Device | cuda |

## Executive Summary

| Metric | EventGPT | Video-LLaVA | Ratio |
|--------|----------|-------------|-------|
| **Prefill Time** | 0.0 ms | 0.0 ms | 1.00x |
| **Total Time** | 0.0 ms | 0.0 ms | 1.00x |
| **Output Tokens** | 0.0 | 0.0 | - |
| **Tokens/sec** | 0.0 | 0.0 | 1.00x |

## Parallel Execution Analysis

| Metric | Value |
|--------|-------|
| **Overlap Window** | 0.0 ms |
| **Hidden Tokens** | 0.0 tokens |
| **Wall-clock (Parallel)** | 0.0 ms |
| **Wall-clock (Sequential)** | 0.0 ms |
| **Parallel Speedup** | 0.00x |

### What This Means

- **Overlap Window**: Time after EventGPT prefill completes but Video-LLaVA is still prefilling
- **Hidden Tokens**: EventGPT draft tokens generated "for free" during VL's prefill
- **Parallel Speedup**: Speedup from running both models simultaneously vs sequentially

## 5-Stage Timing Breakdown

### EventGPT

| Stage | Time (ms) | % of Total |
|-------|-----------|------------|
| Stage 1: Data Loading | 0.0 ± 0.0 | 0.0% |
| Stage 2: Preprocessing | 0.0 ± 0.0 | 0.0% |
| Stage 3: Vision Encoding | 0.0 ± 0.0 | 0.0% |
| Stage 4: LLM Prefill | 0.0 ± 0.0 | 0.0% |
| Stage 5: LLM Decode | 0.0 ± 0.0 | 0.0% |
| **TOTAL** | 0.0 | 100% |

### Video-LLaVA

| Stage | Time (ms) | % of Total |
|-------|-----------|------------|
| Stage 1: Data Loading | 0.0 ± 0.0 | 0.0% |
| Stage 2: Preprocessing | 0.0 ± 0.0 | 0.0% |
| Stage 3: Vision Encoding | 0.0 ± 0.0 | 0.0% |
| Stage 4: LLM Prefill | 0.0 ± 0.0 | 0.0% |
| Stage 5: LLM Decode | 0.0 ± 0.0 | 0.0% |
| **TOTAL** | 0.0 | 100% |

## Sample Outputs (Verification)


## Key Findings

1. **EventGPT Prefill**: 0.0 ms (faster by 1.00x)
2. **Overlap Window**: 0.0 ms available for "free" draft tokens
3. **Hidden Tokens**: ~0 tokens can be generated during VL prefill
4. **Overall Speedup**: EventGPT is 1.00x faster

## Implications for Speculative Decoding

If using EventGPT as draft model for Video-LLaVA:
- 0 draft tokens can be pre-generated during VL prefill
- This represents 0.0% of EventGPT's output
- Effective acceptance rate needed for breakeven: ~100%

---

*Generated: 2026-01-27 00:40:55*
*Author: Alice Zhang*
